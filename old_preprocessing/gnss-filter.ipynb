{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b2da485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "%pip install shapely -q\n",
    "%pip install folium -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7791a76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROSBAGS_DIR_NAS: /home/nepomuk/sflnas/DataReadOnly334/tractor_data/autorecord\n",
      "IMAGES_PER_TOPIC_DIR: /home/nepomuk/sflnas/DataReadWrite334/0_shared/Feldschwarm/bagseek/src/extracted_images_per_topic\n",
      "OUTPUT_DIR: /mnt/data/gnss_aligned_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from rosbags.rosbag2 import Reader\n",
    "from rosbags.typesys import Stores, get_typestore\n",
    "\n",
    "# Load environment variables\n",
    "PARENT_ENV = Path(__file__).resolve().parents[1] / \".env\" if '__file__' in globals() else Path.cwd().parent / \".env\"\n",
    "load_dotenv(dotenv_path=PARENT_ENV)\n",
    "\n",
    "# Define paths\n",
    "ROSBAGS_DIR_NAS = os.getenv(\"ROSBAGS_DIR_NAS\")\n",
    "IMAGES_PER_TOPIC_DIR = os.getenv(\"IMAGES_PER_TOPIC_DIR\")\n",
    "GNSS_FILTER = \"/mnt/data/gps_filter/polygons/oberholz.json\"\n",
    "POLYGON_BUFFER_METERS = 30  # Shrink polygon by 30 meters inward for safety\n",
    "OUTPUT_DIR = Path(\"/mnt/data/gnss_aligned_data\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create typestore for message deserialization\n",
    "typestore = get_typestore(Stores.LATEST)\n",
    "\n",
    "print(f\"ROSBAGS_DIR_NAS: {ROSBAGS_DIR_NAS}\")\n",
    "print(f\"IMAGES_PER_TOPIC_DIR: {IMAGES_PER_TOPIC_DIR}\")\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cb64b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded GPS polygon with 0 points\n"
     ]
    }
   ],
   "source": [
    "# GPS Polygon Filter\n",
    "\n",
    "def load_gps_polygon(polygon_file):\n",
    "    \"\"\"Load GPS polygon from JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(polygon_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract coordinates - handle multiple formats\n",
    "        if \"coordinates\" in data:\n",
    "            # GeoJSON format: {\"coordinates\": [[[lon, lat], [lon, lat], ...]] }\n",
    "            coords = data[\"coordinates\"]\n",
    "            # Handle nested lists (GeoJSON MultiPolygon or Polygon)\n",
    "            if isinstance(coords[0][0], list):\n",
    "                # Nested: take first polygon\n",
    "                coords = coords[0]\n",
    "            # Convert [lon, lat] to (lat, lon)\n",
    "            polygon = [(coord[1], coord[0]) for coord in coords]\n",
    "        elif \"polygon\" in data:\n",
    "            # Simple format: [{\"lat\": ..., \"lon\": ...}, ...]\n",
    "            polygon = [(p[\"lat\"], p[\"lon\"]) for p in data[\"polygon\"]]\n",
    "        else:\n",
    "            # Try to parse as list directly\n",
    "            polygon = data if isinstance(data, list) else []\n",
    "        \n",
    "        print(f\"✓ Loaded GPS polygon with {len(polygon)} points\")\n",
    "        return polygon\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Warning: Could not load GPS polygon: {e}\")\n",
    "        return None\n",
    "\n",
    "def point_in_polygon(lat, lon, polygons):\n",
    "    \"\"\"\n",
    "    Check if a point (lat, lon) is inside any of the polygons using ray-casting algorithm.\n",
    "    \n",
    "    Args:\n",
    "        lat: Latitude of the point\n",
    "        lon: Longitude of the point\n",
    "        polygons: List of polygons, where each polygon is a list of (lat, lon) tuples\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if point is inside any polygon, False otherwise\n",
    "    \"\"\"\n",
    "    # Handle both single polygon and list of polygons\n",
    "    if not polygons:\n",
    "        return False\n",
    "    \n",
    "    # If it's a single polygon (list of tuples), wrap it in a list\n",
    "    if len(polygons) > 0 and isinstance(polygons[0], tuple) and len(polygons[0]) == 2:\n",
    "        polygons = [polygons]\n",
    "    \n",
    "    # Check if point is inside ANY of the polygons\n",
    "    for polygon in polygons:\n",
    "        if not polygon or len(polygon) < 3:\n",
    "            continue\n",
    "        \n",
    "        n = len(polygon)\n",
    "        inside = False\n",
    "        \n",
    "        p1_lat, p1_lon = polygon[0]\n",
    "        for i in range(1, n + 1):\n",
    "            p2_lat, p2_lon = polygon[i % n]\n",
    "            \n",
    "            # Check if point is on an edge (ray crosses the edge)\n",
    "            if lon > min(p1_lon, p2_lon):\n",
    "                if lon <= max(p1_lon, p2_lon):\n",
    "                    if lat <= max(p1_lat, p2_lat):\n",
    "                        if p1_lon != p2_lon:\n",
    "                            x_intersection = (lon - p1_lon) * (p2_lat - p1_lat) / (p2_lon - p1_lon) + p1_lat\n",
    "                        if p1_lat == p2_lat or lat <= x_intersection:\n",
    "                            inside = not inside\n",
    "            \n",
    "            p1_lat, p1_lon = p2_lat, p2_lon\n",
    "        \n",
    "        # If point is inside this polygon, return True immediately\n",
    "        if inside:\n",
    "            return True\n",
    "    \n",
    "    # Not inside any polygon\n",
    "    return False\n",
    "\n",
    "def buffer_polygon_inward(polygon, buffer_meters):\n",
    "    \"\"\"\n",
    "    Shrink polygon inward by specified meters using shapely.\n",
    "    Can return multiple polygons if buffer splits the original polygon.\n",
    "    \n",
    "    Args:\n",
    "        polygon: List of (lat, lon) tuples\n",
    "        buffer_meters: Distance in meters to shrink inward (positive = shrink, negative = expand)\n",
    "    \n",
    "    Returns:\n",
    "        List of polygons, where each polygon is a list of (lat, lon) tuples\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from shapely.geometry import Polygon\n",
    "        \n",
    "        # Convert to (lon, lat) for shapely\n",
    "        coords_lonlat = [(lon, lat) for lat, lon in polygon]\n",
    "        poly = Polygon(coords_lonlat)\n",
    "        \n",
    "        # Approximate conversion: meters to degrees\n",
    "        # At latitude ~51°: 1 degree lat ≈ 111km, 1 degree lon ≈ 70km\n",
    "        avg_lat = sum(lat for lat, lon in polygon) / len(polygon)\n",
    "        meters_per_degree_lat = 111000\n",
    "        meters_per_degree_lon = 111000 * np.cos(np.radians(avg_lat))\n",
    "        \n",
    "        # Convert meters to degrees (negative to shrink inward)\n",
    "        buffer_degrees = -buffer_meters / ((meters_per_degree_lat + meters_per_degree_lon) / 2)\n",
    "        \n",
    "        # Apply buffer\n",
    "        buffered_poly = poly.buffer(buffer_degrees)\n",
    "        \n",
    "        # Convert back to (lat, lon) list\n",
    "        if buffered_poly.is_empty:\n",
    "            print(f\"⚠ Warning: Buffer of {buffer_meters}m too large, polygon disappeared. Using original.\")\n",
    "            return [polygon]\n",
    "        \n",
    "        # Handle MultiPolygon (keep ALL polygons, not just the largest)\n",
    "        polygons = []\n",
    "        if buffered_poly.geom_type == 'MultiPolygon':\n",
    "            # Keep all polygon components\n",
    "            for poly_component in buffered_poly.geoms:\n",
    "                buffered_coords = list(poly_component.exterior.coords)\n",
    "                polygons.append([(lat, lon) for lon, lat in buffered_coords])\n",
    "            print(f\"  Note: Buffer split polygon into {len(polygons)} separate areas\")\n",
    "        else:\n",
    "            # Single Polygon\n",
    "            buffered_coords = list(buffered_poly.exterior.coords)\n",
    "            polygons.append([(lat, lon) for lon, lat in buffered_coords])\n",
    "        \n",
    "        return polygons\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"⚠ shapely not installed. Install it to use polygon buffering\")\n",
    "        print(\"  Using original polygon without buffer\")\n",
    "        return [polygon]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error applying buffer: {e}\")\n",
    "        return [polygon]\n",
    "\n",
    "# Load polygon if file exists\n",
    "GPS_POLYGON = None\n",
    "if Path(GNSS_FILTER).exists():\n",
    "    original_polygon = load_gps_polygon(Path(GNSS_FILTER))\n",
    "    \n",
    "    # Apply inward buffer if configured\n",
    "    if original_polygon and POLYGON_BUFFER_METERS > 0:\n",
    "        original_points = len(original_polygon)\n",
    "        GPS_POLYGON = buffer_polygon_inward(original_polygon, POLYGON_BUFFER_METERS)\n",
    "        total_points = sum(len(poly) for poly in GPS_POLYGON)\n",
    "        print(f\"✓ Applied {POLYGON_BUFFER_METERS}m inward buffer ({original_points} pts → {len(GPS_POLYGON)} polygon(s), {total_points} total pts)\")\n",
    "    else:\n",
    "        # No buffer, wrap single polygon in list\n",
    "        GPS_POLYGON = [original_polygon] if original_polygon else None\n",
    "else:\n",
    "    print(f\"⚠ GPS polygon file not found: {GNSS_FILTER}\")\n",
    "    print(\"  Records will not be filtered by location.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59730118",
   "metadata": {},
   "source": [
    "## GPS Polygon Format\n",
    "\n",
    "The `gps_polygon.json` file should contain a polygon defining the allowed area. Supported formats:\n",
    "\n",
    "**Format 1 - GeoJSON style:**\n",
    "```json\n",
    "{\n",
    "  \"coordinates\": [\n",
    "    [longitude1, latitude1],\n",
    "    [longitude2, latitude2],\n",
    "    [longitude3, latitude3]\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Format 2 - Simple style:**\n",
    "```json\n",
    "{\n",
    "  \"polygon\": [\n",
    "    {\"lat\": latitude1, \"lon\": longitude1},\n",
    "    {\"lat\": latitude2, \"lon\": longitude2},\n",
    "    {\"lat\": latitude3, \"lon\": longitude3}\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Each record in the output JSONL will have an `\"in_area\": true/false` field indicating if the GPS coordinates are within this polygon.\n",
    "\n",
    "## Safety Buffer\n",
    "\n",
    "The `POLYGON_BUFFER_METERS` variable (default: 30 meters) shrinks the polygon inward to ensure the camera stays away from edges, streets, etc.\n",
    "\n",
    "- Set to `0` to disable buffering\n",
    "- Set to `30` (default) for 30-meter safety margin\n",
    "- Set to higher values for more conservative filtering\n",
    "\n",
    "The buffer is applied automatically when loading the polygon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7757e69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Alignment functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Alignment functions (from 01_generate_alignment_and_metadata.py)\n",
    "\n",
    "def determine_reference_topic(topic_timestamps):\n",
    "    \"\"\"Determine the topic with the most messages to use as the reference timeline.\"\"\"\n",
    "    return max(topic_timestamps.items(), key=lambda x: len(x[1]))[0]\n",
    "\n",
    "def create_reference_timestamps(timestamps, factor=2):\n",
    "    \"\"\"Create a refined reference timeline with smaller intervals to improve alignment accuracy.\"\"\"\n",
    "    timestamps = sorted(set(timestamps))\n",
    "    diffs = np.diff(timestamps)\n",
    "    mean_interval = np.mean(diffs)\n",
    "    refined_interval = mean_interval / factor\n",
    "    ref_start = timestamps[0]\n",
    "    ref_end = timestamps[-1]\n",
    "    return np.arange(ref_start, ref_end, refined_interval).astype(np.int64)\n",
    "\n",
    "def align_topic_to_reference(topic_ts, ref_ts, max_diff=int(1e8)):\n",
    "    \"\"\"Align timestamps of a topic to the closest reference timestamps within max_diff.\"\"\"\n",
    "    aligned = []\n",
    "    topic_idx = 0\n",
    "    for rt in ref_ts:\n",
    "        while topic_idx + 1 < len(topic_ts) and abs(topic_ts[topic_idx + 1] - rt) < abs(topic_ts[topic_idx] - rt):\n",
    "            topic_idx += 1\n",
    "        closest = topic_ts[topic_idx]\n",
    "        if abs(closest - rt) <= max_diff:\n",
    "            aligned.append(closest)\n",
    "        else:\n",
    "            aligned.append(None)\n",
    "    return aligned\n",
    "\n",
    "def topic_to_directory_name(topic: str) -> str:\n",
    "    \"\"\"Convert topic name to directory-safe name.\"\"\"\n",
    "    return topic.replace(\"/\", \"__\")\n",
    "\n",
    "print(\"✓ Alignment functions loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638051d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data extraction functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Message data extraction functions\n",
    "\n",
    "def extract_gnss_data(msg):\n",
    "    \"\"\"Extract GNSS/GPS data from NavSatFix message.\"\"\"\n",
    "    try:\n",
    "        return {\n",
    "            \"latitude\": float(msg.latitude),\n",
    "            \"longitude\": float(msg.longitude),\n",
    "            \"altitude\": float(msg.altitude),\n",
    "            \"status\": int(msg.status.status) if hasattr(msg, 'status') else None,\n",
    "            \"service\": int(msg.status.service) if hasattr(msg, 'status') else None,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def extract_tf_data(msg):\n",
    "    \"\"\"Extract TF (Transform) data from TFMessage.\"\"\"\n",
    "    try:\n",
    "        transforms = []\n",
    "        for transform in msg.transforms:\n",
    "            tf_data = {\n",
    "                \"child_frame_id\": transform.child_frame_id,\n",
    "                \"header\": {\n",
    "                    \"frame_id\": transform.header.frame_id,\n",
    "                    \"stamp\": {\n",
    "                        \"sec\": int(transform.header.stamp.sec),\n",
    "                        \"nanosec\": int(transform.header.stamp.nanosec)\n",
    "                    }\n",
    "                },\n",
    "                \"transform\": {\n",
    "                    \"translation\": {\n",
    "                        \"x\": float(transform.transform.translation.x),\n",
    "                        \"y\": float(transform.transform.translation.y),\n",
    "                        \"z\": float(transform.transform.translation.z)\n",
    "                    },\n",
    "                    \"rotation\": {\n",
    "                        \"x\": float(transform.transform.rotation.x),\n",
    "                        \"y\": float(transform.transform.rotation.y),\n",
    "                        \"z\": float(transform.transform.rotation.z),\n",
    "                        \"w\": float(transform.transform.rotation.w)\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            transforms.append(tf_data)\n",
    "        return {\"transforms\": transforms}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def get_image_path(rosbag_name, topic, timestamp):\n",
    "    \"\"\"Get the relative path to the extracted image file.\"\"\"\n",
    "    topic_dir = topic_to_directory_name(topic)\n",
    "    # Return relative path: extracted_images_per_topic/rosbag_name/topic_dir/timestamp.webp\n",
    "    relative_path = f\"extracted_images_per_topic/{rosbag_name}/{topic_dir}/{timestamp}.webp\"\n",
    "    \n",
    "    # Check if file actually exists (using absolute path)\n",
    "    absolute_path = Path(IMAGES_PER_TOPIC_DIR) / rosbag_name / topic_dir / f\"{timestamp}.webp\"\n",
    "    if absolute_path.exists():\n",
    "        return relative_path\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "print(\"✓ Data extraction functions loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978846f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Main processing function loaded\n"
     ]
    }
   ],
   "source": [
    "def classify_topic_type(topic_name, msg_type):\n",
    "    \"\"\"Classify topic as Image, GNSS, or TF based on message type.\"\"\"\n",
    "    # Only accept the front left camera\n",
    "    if \"Image\" in msg_type:\n",
    "        # Filter for only the front left camera\n",
    "        if \"zed_node\" in topic_name and \"left\" in topic_name:\n",
    "            return \"image\"\n",
    "        return None  # Reject other image topics\n",
    "    elif \"NavSatFix\" in msg_type or \"GPS\" in msg_type or \"GNSS\" in msg_type:\n",
    "        return \"gnss\"\n",
    "    elif topic_name == \"/tf\" or \"TFMessage\" in msg_type:\n",
    "        return \"tf\"\n",
    "    return None\n",
    "\n",
    "def process_rosbag_with_data(rosbag_path, output_jsonl_path):\n",
    "    \"\"\"\n",
    "    Process rosbag and extract aligned data for images, GNSS, and IMU.\n",
    "    \n",
    "    Args:\n",
    "        rosbag_path: Path to the rosbag directory\n",
    "        output_jsonl_path: Path to output JSONL file\n",
    "    \"\"\"\n",
    "    rosbag_name = os.path.basename(rosbag_path)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Processing: {rosbag_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Store timestamps and messages by topic\n",
    "    topic_data = defaultdict(list)\n",
    "    topic_messages = defaultdict(dict)  # topic -> {timestamp: message_data}\n",
    "    topic_types = {}\n",
    "    topic_classifications = {}\n",
    "    \n",
    "    # Read all messages from rosbag\n",
    "    print(\"Reading rosbag...\")\n",
    "    try:\n",
    "        with Reader(rosbag_path) as reader:\n",
    "            for connection, timestamp, rawdata in tqdm(reader.messages(), desc=\"Reading messages\"):\n",
    "                topic = connection.topic\n",
    "                msg_type = connection.msgtype\n",
    "                \n",
    "                # Store message type\n",
    "                if topic not in topic_types:\n",
    "                    topic_types[topic] = msg_type\n",
    "                    topic_classifications[topic] = classify_topic_type(topic, msg_type)\n",
    "                \n",
    "                # Only process image, GNSS, and IMU topics\n",
    "                topic_class = topic_classifications[topic]\n",
    "                if topic_class is None:\n",
    "                    continue\n",
    "                \n",
    "                # Store timestamp\n",
    "                topic_data[topic].append(timestamp)\n",
    "                \n",
    "                # Deserialize and extract data based on topic type\n",
    "                try:\n",
    "                    msg = typestore.deserialize_cdr(rawdata, connection.msgtype)\n",
    "                    \n",
    "                    if topic_class == \"gnss\":\n",
    "                        topic_messages[topic][timestamp] = extract_gnss_data(msg)\n",
    "                    elif topic_class == \"tf\":\n",
    "                        topic_messages[topic][timestamp] = extract_tf_data(msg)\n",
    "                    # For images, we just store the timestamp (path is computed later)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Skip messages that fail to deserialize\n",
    "                    continue\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading rosbag: {e}\")\n",
    "        return\n",
    "    \n",
    "    if not topic_data:\n",
    "        print(\"No relevant topics found in rosbag\")\n",
    "        return\n",
    "    \n",
    "    # Separate topics by classification\n",
    "    image_topics = [t for t, c in topic_classifications.items() if c == \"image\"]\n",
    "    gnss_topics = [t for t, c in topic_classifications.items() if c == \"gnss\"]\n",
    "    tf_topics = [t for t, c in topic_classifications.items() if c == \"tf\"]\n",
    "    \n",
    "    print(f\"\\nFound:\")\n",
    "    print(f\"  Image topics: {len(image_topics)}\")\n",
    "    print(f\"  GNSS topics: {len(gnss_topics)}\")\n",
    "    print(f\"  TF topics: {len(tf_topics)}\")\n",
    "    \n",
    "    # Determine reference topic (use topic with most messages)\n",
    "    ref_topic = determine_reference_topic(topic_data)\n",
    "    print(f\"\\nReference topic: {ref_topic} ({len(topic_data[ref_topic])} messages)\")\n",
    "    \n",
    "    # Create reference timeline\n",
    "    print(\"Creating reference timeline...\")\n",
    "    ref_ts = create_reference_timestamps(topic_data[ref_topic])\n",
    "    print(f\"Reference timeline: {len(ref_ts)} timestamps\")\n",
    "    \n",
    "    # Align all topics to reference\n",
    "    print(\"\\nAligning topics to reference timeline...\")\n",
    "    aligned_data = {}\n",
    "    for topic, timestamps in tqdm(topic_data.items(), desc=\"Aligning topics\"):\n",
    "        aligned_data[topic] = align_topic_to_reference(sorted(timestamps), ref_ts)\n",
    "    \n",
    "    print(f\"\\n✓ Alignment complete\")\n",
    "    return ref_ts, aligned_data, topic_classifications, topic_messages, rosbag_name\n",
    "\n",
    "print(\"✓ Main processing function loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc875a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ JSONL writer function loaded\n"
     ]
    }
   ],
   "source": [
    "def write_aligned_jsonl(ref_ts, aligned_data, topic_classifications, topic_messages, rosbag_name, output_path):\n",
    "    \"\"\"\n",
    "    Write aligned data to JSONL file.\n",
    "    \n",
    "    Each line in the JSONL file represents one reference timestamp with all aligned data.\n",
    "    \"\"\"\n",
    "    print(f\"\\nWriting aligned data to {output_path}...\")\n",
    "    \n",
    "    # Separate topics by type\n",
    "    image_topics = [t for t, c in topic_classifications.items() if c == \"image\"]\n",
    "    gnss_topics = [t for t, c in topic_classifications.items() if c == \"gnss\"]\n",
    "    tf_topics = [t for t, c in topic_classifications.items() if c == \"tf\"]\n",
    "    \n",
    "    records_written = 0\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        for i, ref_time in enumerate(tqdm(ref_ts, desc=\"Writing JSONL\")):\n",
    "            record = {\n",
    "                \"reference_timestamp\": int(ref_time),\n",
    "                \"images\": {},\n",
    "                \"gnss\": {},\n",
    "                \"tf\": {}\n",
    "            }\n",
    "            \n",
    "            # Add aligned image data\n",
    "            for topic in image_topics:\n",
    "                aligned_ts = aligned_data[topic][i]\n",
    "                if aligned_ts is not None:\n",
    "                    image_path = get_image_path(rosbag_name, topic, aligned_ts)\n",
    "                    record[\"images\"][topic] = {\n",
    "                        \"timestamp\": int(aligned_ts),\n",
    "                        \"path\": image_path\n",
    "                    }\n",
    "            \n",
    "            # Add aligned GNSS data\n",
    "            for topic in gnss_topics:\n",
    "                aligned_ts = aligned_data[topic][i]\n",
    "                if aligned_ts is not None:\n",
    "                    gnss_data = topic_messages[topic].get(aligned_ts)\n",
    "                    if gnss_data:\n",
    "                        record[\"gnss\"][topic] = {\n",
    "                            \"timestamp\": int(aligned_ts),\n",
    "                            \"data\": gnss_data\n",
    "                        }\n",
    "            \n",
    "            # Add aligned TF data\n",
    "            for topic in tf_topics:\n",
    "                aligned_ts = aligned_data[topic][i]\n",
    "                if aligned_ts is not None:\n",
    "                    tf_data = topic_messages[topic].get(aligned_ts)\n",
    "                    if tf_data:\n",
    "                        record[\"tf\"][topic] = {\n",
    "                            \"timestamp\": int(aligned_ts),\n",
    "                            \"data\": tf_data\n",
    "                        }\n",
    "            \n",
    "            # Check if location is within polygon (using first GNSS topic if available)\n",
    "            in_area = False\n",
    "            if GPS_POLYGON and record[\"gnss\"]:\n",
    "                # Get first GNSS topic data\n",
    "                first_gnss = next(iter(record[\"gnss\"].values()), None)\n",
    "                if first_gnss and \"data\" in first_gnss:\n",
    "                    gnss_data = first_gnss[\"data\"]\n",
    "                    if \"latitude\" in gnss_data and \"longitude\" in gnss_data:\n",
    "                        lat = gnss_data[\"latitude\"]\n",
    "                        lon = gnss_data[\"longitude\"]\n",
    "                        in_area = point_in_polygon(lat, lon, GPS_POLYGON)\n",
    "            \n",
    "            record[\"in_area\"] = in_area\n",
    "            \n",
    "            # Write record as JSON line\n",
    "            f.write(json.dumps(record) + '\\n')\n",
    "            records_written += 1\n",
    "    \n",
    "    print(f\"✓ Wrote {records_written} aligned records to {output_path}\")\n",
    "    return records_written\n",
    "\n",
    "print(\"✓ JSONL writer function loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba6b86",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "\n",
    "Process a single rosbag and generate aligned JSONL data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d708aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Processing: rosbag2_2025_09_24-14_13_40\n",
      "================================================================================\n",
      "Reading rosbag...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading messages: 10581it [00:14, 749.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found:\n",
      "  Image topics: 1\n",
      "  GNSS topics: 1\n",
      "  TF topics: 2\n",
      "\n",
      "Reference topic: /tf (3303 messages)\n",
      "Creating reference timeline...\n",
      "Reference timeline: 6605 timestamps\n",
      "\n",
      "Aligning topics to reference timeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning topics: 100%|██████████| 4/4 [00:00<00:00, 484.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Alignment complete\n",
      "\n",
      "Writing aligned data to /mnt/data/gnss_aligned_data/rosbag2_2025_09_24-14_13_40_aligned.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing JSONL: 100%|██████████| 6605/6605 [00:00<00:00, 44083.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wrote 6605 aligned records to /mnt/data/gnss_aligned_data/rosbag2_2025_09_24-14_13_40_aligned.jsonl\n",
      "\n",
      "✅ Success! Aligned data saved to: /mnt/data/gnss_aligned_data/rosbag2_2025_09_24-14_13_40_aligned.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Process a single rosbag\n",
    "# Change this to the rosbag you want to process\n",
    "\n",
    "#rosbag_name = \"rosbag2_2025_09_25-08_05_56\"  # Change this to your rosbag\n",
    "#rosbag_path = os.path.join(ROSBAGS_DIR_NAS, rosbag_name)\n",
    "rosbag_path = \"/home/nepomuk/sflnas/DataReadOnly334/tractor_data/autorecord/rosbag2_2025_09_24-14_13_40\"\n",
    "rosbag_name = os.path.basename(rosbag_path)\n",
    "output_jsonl = OUTPUT_DIR / f\"{rosbag_name}_aligned.jsonl\"\n",
    "\n",
    "if os.path.exists(rosbag_path):\n",
    "    result = process_rosbag_with_data(rosbag_path, output_jsonl)\n",
    "    \n",
    "    if result:\n",
    "        ref_ts, aligned_data, topic_classifications, topic_messages, bag_name = result\n",
    "        records_written = write_aligned_jsonl(\n",
    "            ref_ts, aligned_data, topic_classifications, \n",
    "            topic_messages, bag_name, output_jsonl\n",
    "        )\n",
    "        print(f\"\\n✅ Success! Aligned data saved to: {output_jsonl}\")\n",
    "    else:\n",
    "        print(\"❌ Failed to process rosbag\")\n",
    "else:\n",
    "    print(f\"❌ Rosbag not found: {rosbag_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd8016",
   "metadata": {},
   "source": [
    "## Preview Output\n",
    "\n",
    "View the first few records from the generated JSONL file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cfd3f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPS polygon loaded\n"
     ]
    }
   ],
   "source": [
    "# Test the polygon with a known point\n",
    "test_lat = 51.256709\n",
    "test_lon = 12.520784\n",
    "\n",
    "if GPS_POLYGON:\n",
    "    # Check if point is in any of the polygons\n",
    "    in_polygon = point_in_polygon(test_lat, test_lon, GPS_POLYGON)\n",
    "    print(f\"Test point: lat={test_lat}, lon={test_lon}\")\n",
    "    print(f\"Point in polygon: {in_polygon}\")\n",
    "    \n",
    "    # Handle multiple polygons\n",
    "    if isinstance(GPS_POLYGON[0], tuple):\n",
    "        # Single polygon\n",
    "        polygons = [GPS_POLYGON]\n",
    "    else:\n",
    "        # Multiple polygons\n",
    "        polygons = GPS_POLYGON\n",
    "    \n",
    "    print(f\"\\nPolygon bounds:\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    # Flatten all coordinates from all polygons\n",
    "    all_coords = []\n",
    "    for polygon in polygons:\n",
    "        for lat, lon in polygon:\n",
    "            all_coords.append((lat, lon))\n",
    "    \n",
    "    all_lats = [coord[0] for coord in all_coords]\n",
    "    all_lons = [coord[1] for coord in all_coords]\n",
    "    \n",
    "    print(f\"  Latitude range: {min(all_lats):.6f} to {max(all_lats):.6f}\")\n",
    "    print(f\"  Longitude range: {min(all_lons):.6f} to {max(all_lons):.6f}\")\n",
    "    print(f\"\\nPolygon points (first 5):\")\n",
    "    for i, (lat, lon) in enumerate(all_coords[:5]):\n",
    "        print(f\"  {i+1}: lat={lat:.6f}, lon={lon:.6f}\")\n",
    "    \n",
    "    print(f\"\\nTotal points: {len(all_coords)}\")\n",
    "    print(f\"Number of polygons: {len(polygons)}\")\n",
    "else:\n",
    "    print(\"No GPS polygon loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52e27230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Visualization function loaded\n"
     ]
    }
   ],
   "source": [
    "# Visualization: Plot polygon and GPS path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_polygon_and_path(polygons, jsonl_path, max_points=None):\n",
    "    \"\"\"\n",
    "    Plot the GPS polygon(s) and the rosbag's GPS path.\n",
    "    \n",
    "    Args:\n",
    "        polygons: List of polygons, where each polygon is a list of (lat, lon) tuples\n",
    "        jsonl_path: Path to the JSONL file with GPS data\n",
    "        max_points: Maximum number of GPS points to plot (for performance)\n",
    "    \"\"\"\n",
    "    if not polygons:\n",
    "        print(\"No polygons loaded\")\n",
    "        return\n",
    "    \n",
    "    # Handle single polygon wrapped in list\n",
    "    if isinstance(polygons[0], tuple):\n",
    "        polygons = [polygons]\n",
    "    \n",
    "    # Extract GPS points from JSONL\n",
    "    gps_points_inside = []\n",
    "    gps_points_outside = []\n",
    "    \n",
    "    with open(jsonl_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if max_points is not None and i >= max_points:\n",
    "                break\n",
    "            record = json.loads(line)\n",
    "            if record.get(\"gnss\"):\n",
    "                first_gnss = next(iter(record[\"gnss\"].values()), None)\n",
    "                if first_gnss and \"data\" in first_gnss:\n",
    "                    lat = first_gnss[\"data\"][\"latitude\"]\n",
    "                    lon = first_gnss[\"data\"][\"longitude\"]\n",
    "                    \n",
    "                    if record.get(\"in_area\"):\n",
    "                        gps_points_inside.append((lat, lon))\n",
    "                    else:\n",
    "                        gps_points_outside.append((lat, lon))\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot all polygons\n",
    "    for idx, polygon in enumerate(polygons):\n",
    "        poly_lats = [p[0] for p in polygon]\n",
    "        poly_lons = [p[1] for p in polygon]\n",
    "        \n",
    "        # Close the polygon for plotting\n",
    "        poly_lats_closed = poly_lats + [poly_lats[0]]\n",
    "        poly_lons_closed = poly_lons + [poly_lons[0]]\n",
    "        \n",
    "        label = f'Polygon {idx+1}' if len(polygons) > 1 else 'Polygon boundary'\n",
    "        plt.plot(poly_lons_closed, poly_lats_closed, 'b-', linewidth=2, label=label if idx == 0 or len(polygons) > 1 else None)\n",
    "        plt.fill(poly_lons_closed, poly_lats_closed, alpha=0.1, color='blue')\n",
    "    \n",
    "    # Plot GPS points inside polygon\n",
    "    if gps_points_inside:\n",
    "        inside_lats = [p[0] for p in gps_points_inside]\n",
    "        inside_lons = [p[1] for p in gps_points_inside]\n",
    "        plt.scatter(inside_lons, inside_lats, c='green', s=10, alpha=0.5, label=f'Inside ({len(gps_points_inside)} points)')\n",
    "    \n",
    "    # Plot GPS points outside polygon\n",
    "    if gps_points_outside:\n",
    "        outside_lats = [p[0] for p in gps_points_outside]\n",
    "        outside_lons = [p[1] for p in gps_points_outside]\n",
    "        plt.scatter(outside_lons, outside_lats, c='red', s=10, alpha=0.5, label=f'Outside ({len(gps_points_outside)} points)')\n",
    "    \n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('GPS Polygon and Rosbag Path')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Points inside polygon: {len(gps_points_inside)}\")\n",
    "    print(f\"  Points outside polygon: {len(gps_points_outside)}\")\n",
    "    print(f\"  Total points plotted: {len(gps_points_inside) + len(gps_points_outside)}\")\n",
    "\n",
    "print(\"✓ Visualization function loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e294c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ GPS polygon not loaded\n"
     ]
    }
   ],
   "source": [
    "# Visualize polygon and rosbag GPS path (ALL points)\n",
    "if GPS_POLYGON and output_jsonl.exists():\n",
    "    plot_polygon_and_path(GPS_POLYGON, output_jsonl, max_points=None)\n",
    "else:\n",
    "    if not GPS_POLYGON:\n",
    "        print(\"❌ GPS polygon not loaded\")\n",
    "    if not output_jsonl.exists():\n",
    "        print(f\"❌ JSONL file not found: {output_jsonl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d91f05",
   "metadata": {},
   "source": [
    "## Interactive Map (Optional)\n",
    "\n",
    "For an interactive map with zoom/pan capabilities, install folium: `pip install folium`\n",
    "\n",
    "Then run the cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d39397a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPS polygon or JSONL file not available\n"
     ]
    }
   ],
   "source": [
    "# Interactive map with folium (optional - requires: pip install folium)\n",
    "try:\n",
    "    import folium\n",
    "    from folium import plugins\n",
    "    \n",
    "    if GPS_POLYGON and output_jsonl.exists():\n",
    "        # Handle single polygon or list of polygons\n",
    "        polygons = GPS_POLYGON if isinstance(GPS_POLYGON, list) else [GPS_POLYGON]\n",
    "        if isinstance(polygons[0], tuple):\n",
    "            polygons = [polygons]\n",
    "        \n",
    "        # Calculate center from all polygons\n",
    "        all_lats = []\n",
    "        all_lons = []\n",
    "        for poly in polygons:\n",
    "            all_lats.extend([p[0] for p in poly])\n",
    "            all_lons.extend([p[1] for p in poly])\n",
    "        \n",
    "        center_lat = sum(all_lats) / len(all_lats)\n",
    "        center_lon = sum(all_lons) / len(all_lons)\n",
    "        \n",
    "        # Create map centered on polygon\n",
    "        m = folium.Map(location=[center_lat, center_lon], zoom_start=15)     \n",
    "        # Add all polygons to map\n",
    "        for idx, polygon in enumerate(polygons):\n",
    "            polygon_coords = [(lat, lon) for lat, lon in polygon]\n",
    "            popup_text = f'Allowed Area {idx+1}' if len(polygons) > 1 else 'Allowed Area'\n",
    "            folium.Polygon(\n",
    "                locations=polygon_coords,\n",
    "                color='blue',\n",
    "                fill=True,\n",
    "                fillColor='blue',\n",
    "                fillOpacity=0.1,\n",
    "                popup=popup_text\n",
    "            ).add_to(m)\n",
    "        \n",
    "        # Extract GPS points from JSONL\n",
    "        inside_points = []\n",
    "        outside_points = []\n",
    "        \n",
    "        with open(output_jsonl, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                record = json.loads(line)\n",
    "                if record.get(\"gnss\"):\n",
    "                    first_gnss = next(iter(record[\"gnss\"].values()), None)\n",
    "                    if first_gnss and \"data\" in first_gnss:\n",
    "                        lat = first_gnss[\"data\"][\"latitude\"]\n",
    "                        lon = first_gnss[\"data\"][\"longitude\"]\n",
    "                        \n",
    "                        if record.get(\"in_area\"):\n",
    "                            inside_points.append([lat, lon])\n",
    "                        else:\n",
    "                            outside_points.append([lat, lon])\n",
    "        \n",
    "        # Add GPS points as circles (display only every 10th point)\n",
    "        for i, (lat, lon) in enumerate(inside_points):\n",
    "            if i % 10 == 0:  # Only display every 10th point\n",
    "                folium.CircleMarker(\n",
    "                    location=[lat, lon],\n",
    "                    radius=2,\n",
    "                    color='green',\n",
    "                    fill=True,\n",
    "                    fillOpacity=0.6\n",
    "                ).add_to(m)\n",
    "\n",
    "        for i, (lat, lon) in enumerate(outside_points):\n",
    "            if i % 10 == 0:  # Only display every 10th point\n",
    "                folium.CircleMarker(\n",
    "                    location=[lat, lon],\n",
    "                    radius=2,\n",
    "                    color='red',\n",
    "                    fill=True,\n",
    "                    fillOpacity=0.6\n",
    "                ).add_to(m)\n",
    "        \n",
    "        # Add legend\n",
    "        legend_html = f'''\n",
    "        <div style=\"position: fixed; top: 10px; right: 10px; z-index:9999; \n",
    "                    background-color: white; padding: 10px; border: 2px solid grey; border-radius: 5px;\">\n",
    "        <p style=\"margin: 0;\"><b>Legend</b></p>\n",
    "        <p style=\"margin: 0;\"><span style=\"color: blue;\">━</span> Polygon boundary</p>\n",
    "        <p style=\"margin: 0;\"><span style=\"color: green;\">●</span> Inside ({len(inside_points)} points)</p>\n",
    "        <p style=\"margin: 0;\"><span style=\"color: red;\">●</span> Outside ({len(outside_points)} points)</p>\n",
    "        </div>\n",
    "        '''\n",
    "        m.get_root().html.add_child(folium.Element(legend_html))\n",
    "        \n",
    "        # Save and display map\n",
    "        map_path = OUTPUT_DIR / \"gps_map.html\"\n",
    "        m.save(str(map_path))\n",
    "        print(f\"✓ Interactive map saved to: {map_path}\")\n",
    "        print(f\"  Open in browser to explore\")\n",
    "        \n",
    "        # Display in notebook\n",
    "        display(m)\n",
    "    else:\n",
    "        print(\"GPS polygon or JSONL file not available\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"⚠ folium not installed. Run: pip install folium\")\n",
    "    print(\"  Or use the matplotlib visualization above\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3757dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: /mnt/data/gnss_aligned_data/rosbag2_2025_09_24-14_13_40_aligned.jsonl\n",
      "\n",
      "Record 1:\n",
      "{\n",
      "  \"reference_timestamp\": 1758716025945350144,\n",
      "  \"images\": {\n",
      "    \"/zed/zed_node/left_raw/image_raw_color/compressed\": {\n",
      "      \"timestamp\": 1758716025921818400,\n",
      "      \"path\": null\n",
      "    }\n",
      "  },\n",
      "  \"gnss\": {\n",
      "    \"/novatel/oem7/fix\": {\n",
      "      \"timestamp\": 1758716025946286816,\n",
      "      \"data\": {\n",
      "        \"latitude\": 51.25794017277804,\n",
      "        \"longitude\": 12.535126753042976,\n",
      "        \"altitude\": 200.46885417960584,\n",
      "        \"status\": 0,\n",
      "        \"service\": 15\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"tf\": {\n",
      "    \"/tf\": {\n",
      "      \"timestamp\": 1758716025945350048,\n",
      "      \"data\": {\n",
      "        \"transforms\": [\n",
      "          {\n",
      "            \"child_frame_id\": \"zed_camera_link\",\n",
      "            \"header\": {\n",
      "              \"frame_id\": \"odom\",\n",
      "              \"stamp\": {\n",
      "                \"sec\": 1758716025,\n",
      "                \"nanosec\": 755078664\n",
      "              }\n",
      "            },\n",
      "            \"transform\": {\n",
      "              \"translation\": {\n",
      "                \"x\": 0.0,\n",
      "                \"y\": 0.0,\n",
      "                \"z\": 0.0\n",
      "              },\n",
      "              \"rotation\": {\n",
      "                \"x\": 0.0,\n",
      "                \"y\": 0.0,\n",
      "                \"z\": 0.0,\n",
      "                \"w\": 1.0\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"in_area\": false\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Record 2:\n",
      "{\n",
      "  \"reference_timestamp\": 1758716025947599360,\n",
      "  \"images\": {\n",
      "    \"/zed/zed_node/left_raw/image_raw_color/compressed\": {\n",
      "      \"timestamp\": 1758716025921818400,\n",
      "      \"path\": null\n",
      "    }\n",
      "  },\n",
      "  \"gnss\": {\n",
      "    \"/novatel/oem7/fix\": {\n",
      "      \"timestamp\": 1758716025946286816,\n",
      "      \"data\": {\n",
      "        \"latitude\": 51.25794017277804,\n",
      "        \"longitude\": 12.535126753042976,\n",
      "        \"altitude\": 200.46885417960584,\n",
      "        \"status\": 0,\n",
      "        \"service\": 15\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"tf\": {\n",
      "    \"/tf\": {\n",
      "      \"timestamp\": 1758716025945429056,\n",
      "      \"data\": {\n",
      "        \"transforms\": [\n",
      "          {\n",
      "            \"child_frame_id\": \"odom\",\n",
      "            \"header\": {\n",
      "              \"frame_id\": \"map\",\n",
      "              \"stamp\": {\n",
      "                \"sec\": 1758716025,\n",
      "                \"nanosec\": 755078664\n",
      "              }\n",
      "            },\n",
      "            \"transform\": {\n",
      "              \"translation\": {\n",
      "                \"x\": 5.058104976529698e-11,\n",
      "                \"y\": 2.649238398100273e-10,\n",
      "                \"z\": -6.993447418390808e-10\n",
      "              },\n",
      "              \"rotation\": {\n",
      "                \"x\": -0.026567783050717553,\n",
      "                \"y\": 0.2504808291987899,\n",
      "                \"z\": -0.0077781057459916534,\n",
      "                \"w\": 0.9677256884978619\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"in_area\": false\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Record 3:\n",
      "{\n",
      "  \"reference_timestamp\": 1758716025949848576,\n",
      "  \"images\": {\n",
      "    \"/zed/zed_node/left_raw/image_raw_color/compressed\": {\n",
      "      \"timestamp\": 1758716025921818400,\n",
      "      \"path\": null\n",
      "    }\n",
      "  },\n",
      "  \"gnss\": {\n",
      "    \"/novatel/oem7/fix\": {\n",
      "      \"timestamp\": 1758716025946286816,\n",
      "      \"data\": {\n",
      "        \"latitude\": 51.25794017277804,\n",
      "        \"longitude\": 12.535126753042976,\n",
      "        \"altitude\": 200.46885417960584,\n",
      "        \"status\": 0,\n",
      "        \"service\": 15\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"tf\": {\n",
      "    \"/tf\": {\n",
      "      \"timestamp\": 1758716025945429056,\n",
      "      \"data\": {\n",
      "        \"transforms\": [\n",
      "          {\n",
      "            \"child_frame_id\": \"odom\",\n",
      "            \"header\": {\n",
      "              \"frame_id\": \"map\",\n",
      "              \"stamp\": {\n",
      "                \"sec\": 1758716025,\n",
      "                \"nanosec\": 755078664\n",
      "              }\n",
      "            },\n",
      "            \"transform\": {\n",
      "              \"translation\": {\n",
      "                \"x\": 5.058104976529698e-11,\n",
      "                \"y\": 2.649238398100273e-10,\n",
      "                \"z\": -6.993447418390808e-10\n",
      "              },\n",
      "              \"rotation\": {\n",
      "                \"x\": -0.026567783050717553,\n",
      "                \"y\": 0.2504808291987899,\n",
      "                \"z\": -0.0077781057459916534,\n",
      "                \"w\": 0.9677256884978619\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"in_area\": false\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Total records in file: 6,605\n"
     ]
    }
   ],
   "source": [
    "# Preview first 3 records from JSONL file\n",
    "import json\n",
    "\n",
    "if output_jsonl.exists():\n",
    "    print(f\"Reading from: {output_jsonl}\\n\")\n",
    "    with open(output_jsonl, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 3:  # Show first 3 records\n",
    "                break\n",
    "            record = json.loads(line)\n",
    "            print(f\"Record {i+1}:\")\n",
    "            print(json.dumps(record, indent=2))\n",
    "            print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Count total records\n",
    "    with open(output_jsonl, 'r') as f:\n",
    "        total = sum(1 for _ in f)\n",
    "    print(f\"Total records in file: {total:,}\")\n",
    "else:\n",
    "    print(f\"Output file not found: {output_jsonl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127edc11",
   "metadata": {},
   "source": [
    "## Batch Processing\n",
    "\n",
    "Process all rosbags in the directory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6098bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing code ready (uncomment to run)\n"
     ]
    }
   ],
   "source": [
    "# Process all rosbags (optional - uncomment to run)\n",
    "\"\"\"\n",
    "succeeded = 0\n",
    "failed = 0\n",
    "\n",
    "for rosbag_dir in os.listdir(ROSBAGS_DIR_NAS):\n",
    "    rosbag_path = os.path.join(ROSBAGS_DIR_NAS, rosbag_dir)\n",
    "    \n",
    "    if not os.path.isdir(rosbag_path):\n",
    "        continue\n",
    "    \n",
    "    # Check if metadata.yaml exists\n",
    "    if not os.path.exists(os.path.join(rosbag_path, \"metadata.yaml\")):\n",
    "        print(f\"Skipping {rosbag_dir} (no metadata.yaml)\")\n",
    "        continue\n",
    "    \n",
    "    # Skip if output already exists\n",
    "    output_jsonl = OUTPUT_DIR / f\"{rosbag_dir}_aligned.jsonl\"\n",
    "    if output_jsonl.exists():\n",
    "        print(f\"Skipping {rosbag_dir} (already processed)\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        result = process_rosbag_with_data(rosbag_path, output_jsonl)\n",
    "        \n",
    "        if result:\n",
    "            ref_ts, aligned_data, topic_classifications, topic_messages, bag_name = result\n",
    "            records_written = write_aligned_jsonl(\n",
    "                ref_ts, aligned_data, topic_classifications, \n",
    "                topic_messages, bag_name, output_jsonl\n",
    "            )\n",
    "            succeeded += 1\n",
    "        else:\n",
    "            failed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Exception processing {rosbag_dir}: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Batch processing complete!\")\n",
    "print(f\"Succeeded: {succeeded}\")\n",
    "print(f\"Failed: {failed}\")\n",
    "print(f\"Total: {succeeded + failed}\")\n",
    "print(f\"{'='*80}\")\n",
    "\"\"\"\n",
    "print(\"Batch processing code ready (uncomment to run)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37b616",
   "metadata": {},
   "source": [
    "## Output Format Example\n",
    "\n",
    "Each line in the JSONL file will look like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"reference_timestamp\": 1740743431773208900,\n",
    "  \"images\": {\n",
    "    \"/camera/rear_left/compressed\": {\n",
    "      \"timestamp\": 1740743431773208900,\n",
    "      \"path\": \"/path/to/extracted_images_per_topic/rosbag_name/__camera__rear_left__compressed/1740743431773208900.webp\"\n",
    "    },\n",
    "    \"/camera/rear_mid/compressed\": {\n",
    "      \"timestamp\": 1740743431740046707,\n",
    "      \"path\": \"/path/to/extracted_images_per_topic/rosbag_name/__camera__rear_mid__compressed/1740743431740046707.webp\"\n",
    "    }\n",
    "  },\n",
    "  \"gnss\": {\n",
    "    \"/gnss/fix\": {\n",
    "      \"timestamp\": 1740743431750000000,\n",
    "      \"data\": {\n",
    "        \"latitude\": 48.123456,\n",
    "        \"longitude\": 11.234567,\n",
    "        \"altitude\": 523.45,\n",
    "        \"status\": 0,\n",
    "        \"service\": 1\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"tf\": {\n",
    "    \"/tf\": {\n",
    "      \"timestamp\": 1740743431760000000,\n",
    "      \"data\": {\n",
    "        \"transforms\": [{\n",
    "          \"child_frame_id\": \"base_link\",\n",
    "          \"header\": {\n",
    "            \"frame_id\": \"odom\",\n",
    "            \"stamp\": {\"sec\": 1740743431, \"nanosec\": 760000000}\n",
    "          },\n",
    "          \"transform\": {\n",
    "            \"translation\": {\"x\": 1.23, \"y\": 0.45, \"z\": 0.0},\n",
    "            \"rotation\": {\"x\": 0.0, \"y\": 0.0, \"z\": 0.1, \"w\": 0.995}\n",
    "          }\n",
    "        }]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68bf7b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside area: 0\n",
      "Outside area: 6605\n",
      "Found 0 images in the allowed area\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Get only records inside the polygon\n",
    "inside_area = []\n",
    "outside_area = []\n",
    "\n",
    "with open(output_jsonl, 'r') as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        if record[\"in_area\"]:\n",
    "            inside_area.append(record)\n",
    "        else:\n",
    "            outside_area.append(record)\n",
    "\n",
    "print(f\"Inside area: {len(inside_area)}\")\n",
    "print(f\"Outside area: {len(outside_area)}\")\n",
    "\n",
    "\n",
    "### Get Images from Specific Area:\n",
    "\n",
    "# Extract image paths for records inside the polygon\n",
    "image_paths = []\n",
    "\n",
    "with open(output_jsonl, 'r') as f:\n",
    "    for line in f:\n",
    "        record = json.loads(line)\n",
    "        if record[\"in_area\"] and record[\"images\"]:\n",
    "            for topic, img_data in record[\"images\"].items():\n",
    "                if img_data[\"path\"]:\n",
    "                    image_paths.append(img_data[\"path\"])\n",
    "\n",
    "print(f\"Found {len(image_paths)} images in the allowed area\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bagseek-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
